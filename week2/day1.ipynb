{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Welcome to Week 2!\n",
    "\n",
    "## Frontier Model APIs\n",
    "\n",
    "In Week 1, we used multiple Frontier LLMs through their Chat UI, and we connected with the OpenAI's API.\n",
    "\n",
    "Today we'll connect with the APIs for Anthropic and Google, as well as OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b268b6e-0ba4-461e-af86-74a41f4d681f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Important Note - Please read me</h2>\n",
    "            <span style=\"color:#900;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in an Anaconda prompt (PC) or Terminal (Mac), run:<br/>\n",
    "            <code>conda env update --f environment.yml</code><br/>\n",
    "            Or if you used virtualenv rather than Anaconda, then run this from your activated environment in a Powershell (PC) or Terminal (Mac):<br/>\n",
    "            <code>pip install -r requirements.txt</code>\n",
    "            <br/>Then restart the kernel (Kernel menu >> Restart Kernel and Clear Outputs Of All Cells) to pick up the changes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder about the resources page</h2>\n",
    "            <span style=\"color:#f71;\">Here's a link to resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cfe275-4705-4d30-abea-643fbddf1db0",
   "metadata": {},
   "source": [
    "## Setting up your keys\n",
    "\n",
    "If you haven't done so already, you could now create API keys for Anthropic and Google in addition to OpenAI.\n",
    "\n",
    "**Please note:** if you'd prefer to avoid extra API costs, feel free to skip setting up Anthopic and Google! You can see me do it, and focus on OpenAI for the course. You could also substitute Anthropic and/or Google for Ollama, using the exercise you did in week 1.\n",
    "\n",
    "For OpenAI, visit https://openai.com/api/  \n",
    "For Anthropic, visit https://console.anthropic.com/  \n",
    "For Google, visit https://ai.google.dev/gemini-api  \n",
    "\n",
    "### Also - adding DeepSeek if you wish\n",
    "\n",
    "Optionally, if you'd like to also use DeepSeek, create an account [here](https://platform.deepseek.com/), create a key [here](https://platform.deepseek.com/api_keys) and top up with at least the minimum $2 [here](https://platform.deepseek.com/top_up).\n",
    "\n",
    "### Adding API keys to your .env file\n",
    "\n",
    "When you get your API keys, you need to set them as environment variables by adding them to your `.env` file.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxx\n",
    "ANTHROPIC_API_KEY=xxxx\n",
    "GOOGLE_API_KEY=xxxx\n",
    "DEEPSEEK_API_KEY=xxxx\n",
    "```\n",
    "\n",
    "Afterwards, you may need to restart the Jupyter Lab Kernel (the Python process that sits behind this notebook) via the Kernel menu, and then rerun the cells from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyDJ\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425ed580-808d-429b-85b0-6cba50ca1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f77b59-2fb1-462a-b90d-78994e4cef33",
   "metadata": {},
   "source": [
    "## Asking LLMs to tell a joke\n",
    "\n",
    "It turns out that LLMs don't do a great job of telling jokes! Let's compare a few models.\n",
    "Later we will be putting LLMs to better use!\n",
    "\n",
    "### What information is included in the API\n",
    "\n",
    "Typically we'll pass to the API:\n",
    "- The name of the model that should be used\n",
    "- A system message that gives overall context for the role the LLM is playing\n",
    "- A user message that provides the actual prompt\n",
    "\n",
    "There are other parameters that can be used, including **temperature** which is typically between 0 and 1; higher for more random output; lower for more focused and deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b3879b6-9a55-4fed-a18c-1ea2edfaf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to the bar?\n",
      "\n",
      "Because they heard the drinks were on the house!\n"
     ]
    }
   ],
   "source": [
    "# GPT-3.5-Turbo\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-3.5-turbo', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2d6beb-1b81-466f-8ed1-40bf51e7adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician?\n",
      "\n",
      "Because she found him too mean!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1f54beb-823f-4301-98cb-8b9a49f4ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the logistic regression model?\n",
      "\n",
      "It couldn't handle the relationship's non-linearity!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ecdb506-9f7c-4539-abae-0e78d7f31b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to go to the beach?\n",
      "\n",
      "Because they're afraid of over-fitting their sunscreen!\n",
      "\n",
      "(The joke plays on the statistical concept of \"overfitting\" where a model matches the training data too closely, but in this case it's humorously applied to applying too much sunscreen!)\n"
     ]
    }
   ],
   "source": [
    "# Claude 3.7 Sonnet\n",
    "# API needs system message provided separately from user prompt\n",
    "# Also adding max_tokens\n",
    "\n",
    "message = claude.messages.create(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "769c4017-4b3b-4e64-8da7-ef4dcbe3fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't data scientists like to go to the beach?\n",
      "\n",
      "Because they're afraid of overfitting their sunscreen!\n",
      "\n",
      "(You see, in data science, \"overfitting\" is when your model matches the training data too closely and performs poorly on new data. Just like how you might apply too much sunscreen based on your last beach trip and end up looking like a ghost!)"
     ]
    }
   ],
   "source": [
    "# Claude 3.7 Sonnet again\n",
    "# Now let's add in streaming back results\n",
    "# If the streaming looks strange, then please see the note below this cell!\n",
    "\n",
    "result = claude.messages.stream(\n",
    "    model=\"claude-3-7-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e17bc-cd46-4c23-b639-0c7b748e6c5a",
   "metadata": {},
   "source": [
    "## A rare problem with Claude streaming on some Windows boxes\n",
    "\n",
    "2 students have noticed a strange thing happening with Claude's streaming into Jupyter Lab's output -- it sometimes seems to swallow up parts of the response.\n",
    "\n",
    "To fix this, replace the code:\n",
    "\n",
    "`print(text, end=\"\", flush=True)`\n",
    "\n",
    "with this:\n",
    "\n",
    "`clean_text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")`  \n",
    "`print(clean_text, end=\"\", flush=True)`\n",
    "\n",
    "And it should work fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6df48ce5-70f8-4643-9a50-b0b5bfdb66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the data scientist sad?\n",
      "\n",
      "Because all his relationships were based on algorithms! He just couldn't seem to find real \"variable\" love. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The API for Gemini has a slightly different structure.\n",
    "# I've heard that on some PCs, this Gemini code causes the Kernel to crash.\n",
    "# If that happens to you, please skip this cell and use the next cell instead - an alternative approach.\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49009a30-037d-41c8-b874-127f61c4aa3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why was the Python Data Scientist always calm?\n",
      "\n",
      "Because they knew how to Pandas! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As an alternative way to use Gemini that bypasses Google's python API library,\n",
    "# Google has recently released new endpoints that means you can use Gemini via the client libraries for OpenAI!\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = gemini_via_openai_client.chat.completions.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    messages=prompts\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f70c88-7ca9-470b-ad55-d93a57dcc0ab",
   "metadata": {},
   "source": [
    "## (Optional) Trying out the DeepSeek model\n",
    "\n",
    "### Let's ask DeepSeek a really hard question - both the Chat and the Reasoner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d0019fb-f6a8-45cb-962b-ef8bf7070d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepSeek API Key exists and begins sk-\n"
     ]
    }
   ],
   "source": [
    "# Optionally if you wish to try DeekSeek, you can also use the OpenAI client library\n",
    "\n",
    "load_dotenv(override=True)\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c72c871e-68d6-4668-9c27-96d52b77b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one for the data scientists:\n",
      "\n",
      "**Why did the data scientist bring a ladder to the bar?**\n",
      "\n",
      "Because they heard the drinks were *high-dimensional*!  \n",
      "\n",
      "(And they wanted to *reduce* the dimensions before overfitting their liver.) 🍸📊  \n",
      "\n",
      "Hope that gets a chuckle! Let me know if you'd like another.\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Chat\n",
    "\n",
    "deepseek_via_openai_client = OpenAI(\n",
    "    api_key=deepseek_api_key, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "response = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=prompts,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50b6e70f-700a-46cf-942f-659101ffeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "             {\"role\": \"user\", \"content\": \"How many words are there in your answer to this prompt\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66d1151c-2015-4e37-80c8-16bc16367cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Alright, let's tackle this problem step by step. The question is: \"How many words are there in your answer to this prompt.\" At first glance, it seems straightforward, but when I think about it more deeply, it's actually a bit of a paradox or a self-referential problem. Here's how I'm going to approach it:\n",
       "\n",
       "### Understanding the Problem\n",
       "\n",
       "The question is asking for the word count of the answer that is being generated in response to it. This means that the answer's length (in words) is dependent on the number it's trying to report. \n",
       "\n",
       "Let me rephrase it: If I say, \"This answer contains X words,\" then X must accurately reflect the total number of words in that entire statement. But to know X, I have to count the words in the answer, which includes the statement about the word count itself. This creates a loop where the word count depends on the word count.\n",
       "\n",
       "### Simple Example\n",
       "\n",
       "Let's try a simple example to see how this plays out.\n",
       "\n",
       "Suppose I answer: \"This answer has five words.\"\n",
       "\n",
       "Now, let's count the words in that sentence: \"This\", \"answer\", \"has\", \"five\", \"words.\" That's indeed five words. So in this case, the answer is correct.\n",
       "\n",
       "But what if I say: \"This answer contains seven words.\"\n",
       "\n",
       "Counting: \"This\", \"answer\", \"contains\", \"seven\", \"words.\" That's five words, not seven. So this answer is incorrect.\n",
       "\n",
       "Similarly, \"This answer has four words.\" Count: \"This\", \"answer\", \"has\", \"four\", \"words.\" Five words again, so incorrect.\n",
       "\n",
       "From this, it seems that the only correct answer is the one where the number stated matches the actual word count when you include that number in the count.\n",
       "\n",
       "### Finding the Correct Word Count\n",
       "\n",
       "Let's generalize this. Suppose the answer is: \"This answer has X words.\"\n",
       "\n",
       "Now, let's count the words in this sentence:\n",
       "\n",
       "1. This\n",
       "2. answer\n",
       "3. has\n",
       "4. X\n",
       "5. words\n",
       "\n",
       "So, no matter what X is, the sentence always has 5 words. Therefore, for the statement to be true, X must be 5.\n",
       "\n",
       "Any other number would make the statement false because the sentence structure fixes the word count at 5.\n",
       "\n",
       "### Verifying the Solution\n",
       "\n",
       "Let's verify:\n",
       "\n",
       "Answer: \"This answer has five words.\"\n",
       "\n",
       "Word count: \n",
       "1. This\n",
       "2. answer\n",
       "3. has\n",
       "4. five\n",
       "5. words\n",
       "\n",
       "Yes, it's five words. \n",
       "\n",
       "If we try X = 5: \"This answer has five words.\" → 5 words. Correct.\n",
       "\n",
       "X = 4: \"This answer has four words.\" → \"This\", \"answer\", \"has\", \"four\", \"words.\" → 5 words. But claimed 4. Incorrect.\n",
       "\n",
       "X = 6: \"This answer has six words.\" → 5 words. Incorrect.\n",
       "\n",
       "Thus, the only correct answer is when X = 5.\n",
       "\n",
       "### Considering Alternative Phrasing\n",
       "\n",
       "Could there be another way to phrase the answer that would allow for a different word count? Let's try.\n",
       "\n",
       "Alternative answer: \"The number of words in this answer is five.\"\n",
       "\n",
       "Word count:\n",
       "1. The\n",
       "2. number\n",
       "3. of\n",
       "4. words\n",
       "5. in\n",
       "6. this\n",
       "7. answer\n",
       "8. is\n",
       "9. five\n",
       "\n",
       "That's 9 words. But we're saying it's five, which is incorrect.\n",
       "\n",
       "Another try: \"Five words are in this answer.\"\n",
       "\n",
       "Word count:\n",
       "1. Five\n",
       "2. words\n",
       "3. are\n",
       "4. in\n",
       "5. this\n",
       "6. answer\n",
       "\n",
       "6 words, but claiming five. Incorrect.\n",
       "\n",
       "\"Here are five words in this answer.\"\n",
       "\n",
       "Word count:\n",
       "1. Here\n",
       "2. are\n",
       "3. five\n",
       "4. words\n",
       "5. in\n",
       "6. this\n",
       "7. answer\n",
       "\n",
       "7 words, not five.\n",
       "\n",
       "It seems that the simplest and most accurate phrasing is the initial one: \"This answer has five words,\" which indeed contains five words.\n",
       "\n",
       "### Potential Missteps\n",
       "\n",
       "Initially, one might think that the answer could vary based on how it's phrased, leading to different word counts. However, as seen in the examples, most alternative phrasings either increase the word count beyond the stated number or don't match. The only self-consistent answer is the one where the declaration of the word count itself fits neatly into the total count without excess.\n",
       "\n",
       "Another misstep could be ignoring the self-referential nature of the problem and trying to provide an answer without ensuring that the word count includes the count declaration itself. This would lead to discrepancies where the stated count doesn't match the actual count.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "After carefully considering different phrasings and counting the words in each possible answer, the only accurate and self-consistent answer is:\n",
       "\n",
       "\"This answer has five words.\"\n",
       "\n",
       "Let's count to confirm:\n",
       "1. This\n",
       "2. answer\n",
       "3. has\n",
       "4. five\n",
       "5. words\n",
       "\n",
       "Yes, it's five words. Any other number would make the statement false because the sentence structure dictates that it must be five words.\n",
       "\n",
       "### Final Answer\n",
       "\n",
       "This answer has five words."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 679\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Chat with a harder question! And streaming results\n",
    "\n",
    "stream = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=challenge,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43a93f7d-9300-48cc-8c1a-ee67380db495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user is asking how many words are in my answer to this prompt. Let me think. First, I need to make sure I understand the question correctly. They want the word count of the response I'm about to give.\n",
      "\n",
      "So, when they say \"your answer to this prompt,\" they're referring to the response I'm generating right now. That means I need to calculate the number of words in this very answer. But wait, how do I do that? Well, I can write the response first and then count the words. But since I need to include the count in the response, maybe I should plan ahead.\n",
      "\n",
      "I'll start by composing a clear answer, then count the words. Let me draft it. The answer should explain that I'm providing the word count and then state the number. But I need to be careful not to include the count itself in the word count. Hmm, that's a bit tricky. Let me outline the steps:\n",
      "\n",
      "1. Compose the response explaining the process.\n",
      "2. Count the words in that response.\n",
      "3. Insert the word count at the end, ensuring it's accurate.\n",
      "\n",
      "Wait, but if I include the count in the response, does that add to the word count? For example, if I write \"There are X words in this response,\" the word count would include those words. So, I need to calculate the number of words before inserting X, then adjust X accordingly. This might require an iterative approach. Let me try:\n",
      "\n",
      "Draft the sentence: \"There are X words in this response.\" That's 7 words plus the number. If X is a number like 10, the total would be 7 + 1 (for the number as a word) = 8 words. But the actual count depends on the exact number. Wait, numbers written as digits (like 10) are counted as one word each. So if I write \"10,\" that's one word. So the sentence \"There are 10 words in this response.\" has 7 words (including \"10\" as one word). But if the actual word count is different, I need to adjust.\n",
      "\n",
      "Wait, but how does the word count work here? In typical word counting, numbers written as numerals are considered one word each. So \"10\" is one word. So if my entire response is \"There are X words in this response,\" the total words would be 7, with X being a numeral. But if the actual response is longer, I need to count all words, including the ones in the explanation and the final count.\n",
      "\n",
      "Let me structure the response step by step. First, I need to write the answer, then count the words, then state the count. But since the count is part of the answer, I need to make sure the count includes all words up to and including the count statement. This creates a loop. To resolve this, I can write the entire response except for the count statement, count those words, add the count statement with the number, and then adjust the number accordingly.\n",
      "\n",
      "For example:\n",
      "\n",
      "1. Write: \"The answer to this prompt contains X words.\" Let's say the sentence without X is \"The answer to this prompt contains words.\" That's 7 words. Adding X (as a numeral, e.g., 8) makes it 8 words. But if the actual total is 8, then X would be 8. But how do I know X before writing the sentence? This seems like a chicken and egg problem.\n",
      "\n",
      "Alternatively, perhaps I should write the entire response, including the count statement, and then count all the words, including the number. For example:\n",
      "\n",
      "\"Hello! I'll help you with that. The number of words in this response is X.\"\n",
      "\n",
      "If I write that, then count all the words, including the X as one word, then replace X with the total. But if X is a numeral like 10, which is one word, then the total would be 10 words. Wait, let's try:\n",
      "\n",
      "\"Hello! I'll help you with that. The number of words in this response is 10.\" Let's count:\n",
      "\n",
      "Hello (1), I'll (2), help (3), you (4), with (5), that (6). The (7), number (8), of (9), words (10), in (11), this (12), response (13), is (14), 10 (15). So that's 15 words, but the count says 10. That's inconsistent.\n",
      "\n",
      "This approach doesn't work because the count is part of the total. So the correct way is to write the entire response, then count the words, then adjust the count. For example:\n",
      "\n",
      "1. Compose the response without the count: \"Hello! I'll help you with that. The number of words in this response is X.\"\n",
      "2. Count the words in that sentence. \"Hello\" (1), \"I'll\" (2), \"help\" (3), \"you\" (4), \"with\" (5), \"that\" (6), \"The\" (7), \"number\" (8), \"of\" (9), \"words\" (10), \"in\" (11), \"this\" (12), \"response\" (13), \"is\" (14), \"X\" (15). So 15 words.\n",
      "3. Therefore, X should be 15. But the original sentence with X is 15 words, so replacing X with 15 would make the sentence: \"Hello! I'll help you with that. The number of words in this response is 15.\" Now count again: \"Hello\" (1), \"I'll\" (2), \"help\" (3), \"you\" (4), \"with\" (5), \"that\" (6), \"The\" (7), \"number\" (8), \"of\" (9), \"words\" (10), \"in\" (11), \"this\" (12), \"response\" (13), \"is\" (14), \"15\" (15). So 15 words. Correct.\n",
      "\n",
      "But in the example above, the assistant's response would be the sentence stating there are 15 words, and the count is accurate. However, this requires the assistant to first draft the response, count the words assuming X is a placeholder, then replace X with the correct count. But how can the assistant do this in a single pass?\n",
      "\n",
      "In practice, as a language model, I can generate the response, then count the words in it, and then include the count. But since I have to output the count within the response, I need to ensure that the count includes the entire response, including the count itself. This recursive problem can be solved by making an initial draft, calculating the word count including the count statement, and then adjusting accordingly.\n",
      "\n",
      "Let's try this step by step with the actual response:\n",
      "\n",
      "First draft:\n",
      "\n",
      "\"To determine the number of words in my response, I will first compose this answer and then count the words. The total number of words in this response is X.\"\n",
      "\n",
      "Now, count the words in this draft:\n",
      "\n",
      "\"To\" (1), \"determine\" (2), \"the\" (3), \"number\" (4), \"of\" (5), \"words\" (6), \"in\" (7), \"my\" (8), \"response\" (9), \"I\" (10), \"will\" (11), \"first\" (12), \"compose\" (13), \"this\" (14), \"answer\" (15), \"and\" (16), \"then\" (17), \"count\" (18), \"the\" (19), \"words\" (20), \"The\" (21), \"total\" (22), \"number\" (23), \"of\" (24), \"words\" (25), \"in\" (26), \"this\" (27), \"response\" (28), \"is\" (29), \"X\" (30). Total of 30 words.\n",
      "\n",
      "So, X should be 30. Now replace X with 30:\n",
      "\n",
      "\"To determine the number of words in my response, I will first compose this answer and then count the words. The total number of words in this response is 30.\"\n",
      "\n",
      "Now, count again:\n",
      "\n",
      "Same as before, but \"X\" is replaced by \"30\" (which is one word). So the total remains 30 words. Therefore, the count is accurate.\n",
      "\n",
      "But wait, when replacing X with 30, which is a numeral, it's still one word, so the total remains 30. So this works. Therefore, the correct answer is 30 words in that example.\n",
      "\n",
      "But in the actual case, I need to make sure the response is structured so that when I count the words, including the final number, it's accurate. Therefore, the approach is:\n",
      "\n",
      "1. Write the response, leaving a placeholder for the word count.\n",
      "2. Count the words in the response, including the placeholder as one word.\n",
      "3. Replace the placeholder with the actual count, which is the same as the total from step 2.\n",
      "4. The final count is correct because replacing the placeholder (one word) with the numeral (one word) doesn't change the total.\n",
      "\n",
      "Applying this to the current problem:\n",
      "\n",
      "The user's question is \"How many words are there in your answer to this prompt.\"\n",
      "\n",
      "My response needs to be a sentence that states the word count, and the count must include all words in the response, including the number itself.\n",
      "\n",
      "Let me draft the response:\n",
      "\n",
      "\"There are X words in this response.\"\n",
      "\n",
      "Counting the words in this draft: \"There\" (1), \"are\" (2), \"X\" (3), \"words\" (4), \"in\" (5), \"this\" (6), \"response\" (7). Total of 7 words. Therefore, X should be 7. But if I replace X with 7, the sentence becomes \"There are 7 words in this response.\" Now count again: \"There\" (1), \"are\" (2), \"7\" (3), \"words\" (4), \"in\" (5), \"this\" (6), \"response\" (7). Still 7 words. So the count is accurate.\n",
      "\n",
      "But wait, the user's question might expect a more detailed response. For example, if I just answer with that single sentence, but perhaps the assistant would elaborate more. However, the user's instruction is to provide the answer, which is the count. But the initial instruction says \"You are a helpful assistant,\" so maybe the assistant should provide a more helpful answer, explaining the process.\n",
      "\n",
      "But the user's exact question is \"How many words are there in your answer to this prompt.\" So the answer should be the number, but perhaps with a brief explanation.\n",
      "\n",
      "Let me consider the example from earlier. If I write:\n",
      "\n",
      "\"To determine the number of words in my response, I first compose this answer and then count the words. The total number of words in this response is X.\"\n",
      "\n",
      "Then count the words as before, which was 30 words. But when I replace X with 30, the total becomes 30. However, in reality, when I write the actual response, I need to make sure the count includes everything.\n",
      "\n",
      "Alternatively, maybe the assistant will generate a more concise answer. Let's try a concise version:\n",
      "\n",
      "\"The number of words in this response is X.\"\n",
      "\n",
      "Count: \"The\" (1), \"number\" (2), \"of\" (3), \"words\" (4), \"in\" (5), \"this\" (6), \"response\" (7), \"is\" (8), \"X\" (9). So 9 words. Replace X with 9: \"The number of words in this response is 9.\" Count: 9 words. Correct.\n",
      "\n",
      "But wait, in this case, the count is 9. But the sentence \"The number of words in this response is 9.\" has 9 words, which is correct. So if I output that, it's accurate.\n",
      "\n",
      "However, this seems a bit too concise. The user might expect a slightly more detailed answer. For example, acknowledging the question first.\n",
      "\n",
      "Let me try:\n",
      "\n",
      "\"Hello! The answer to your question is that there are X words in this response.\"\n",
      "\n",
      "Count the words: \"Hello\" (1), \"The\" (2), \"answer\" (3), \"to\" (4), \"your\" (5), \"question\" (6), \"is\" (7), \"that\" (8), \"there\" (9), \"are\" (10), \"X\" (11), \"words\" (12), \"in\" (13), \"this\" (14), \"response\" (15). Total of 15 words. So X is 15. The sentence becomes: \"Hello! The answer to your question is that there are 15 words in this response.\" Count again: 15 words. Correct.\n",
      "\n",
      "But this seems a bit forced. Alternatively, maybe the assistant would write a natural response that includes the count. Let's try:\n",
      "\n",
      "\"To answer your question, I need to count the words in this response. Including this sentence, there are X words in total.\"\n",
      "\n",
      "Count the words: \"To\" (1), \"answer\" (2), \"your\" (3), \"question\" (4), \"I\" (5), \"need\" (6), \"to\" (7), \"count\" (8), \"the\" (9), \"words\" (10), \"in\" (11), \"this\" (12), \"response\" (13), \"Including\" (14), \"this\" (15), \"sentence\" (16), \"there\" (17), \"are\" (18), \"X\" (19), \"words\" (20), \"in\" (21), \"total\" (22). Total of 22 words. So X=22. The sentence becomes: \"To answer your question, I need to count the words in this response. Including this sentence, there are 22 words in total.\" Count again: 22 words. Correct.\n",
      "\n",
      "This approach works. So the key is to construct the response, leaving X as a placeholder, count the words including X as one word, then replace X with the total count, which matches the total number of words.\n",
      "\n",
      "Now, applying this to the current scenario. The user's question is in English, and the assistant needs to respond in English. Let's craft the response:\n",
      "\n",
      "\"To determine the number of words in my answer, I'll compose this response and then count each word. The total word count for this answer is X.\"\n",
      "\n",
      "Now, count the words:\n",
      "\n",
      "\"To\" (1), \"determine\" (2), \"the\" (3), \"number\" (4), \"of\" (5), \"words\" (6), \"in\" (7), \"my\" (8), \"answer\" (9), \"I'll\" (10), \"compose\" (11), \"this\" (12), \"response\" (13), \"and\" (14), \"then\" (15), \"count\" (16), \"each\" (17), \"word\" (18), \"The\" (19), \"total\" (20), \"word\" (21), \"count\" (22), \"for\" (23), \"this\" (24), \"answer\" (25), \"is\" (26), \"X\" (27). Total of 27 words. So X=27. The response becomes:\n",
      "\n",
      "\"To determine the number of words in my answer, I'll compose this response and then count each word. The total word count for this answer is 27.\"\n",
      "\n",
      "Count again: 27 words. Correct.\n",
      "\n",
      "But wait, let's check:\n",
      "\n",
      "\"To determine the number of words in my answer, I'll compose this response and then count each word. The total word count for this answer is 27.\"\n",
      "\n",
      "Breaking it down:\n",
      "\n",
      "1. To\n",
      "2. determine\n",
      "3. the\n",
      "4. number\n",
      "5. of\n",
      "6. words\n",
      "7. in\n",
      "8. my\n",
      "9. answer\n",
      "10. I'll\n",
      "11. compose\n",
      "12. this\n",
      "13. response\n",
      "14. and\n",
      "15. then\n",
      "16. count\n",
      "17. each\n",
      "18. word\n",
      "19. The\n",
      "20. total\n",
      "21. word\n",
      "22. count\n",
      "23. for\n",
      "24. this\n",
      "25. answer\n",
      "26. is\n",
      "27. 27\n",
      "\n",
      "Yes, 27 words. So this works.\n",
      "\n",
      "However, perhaps the assistant's actual response is different. Let's see. In the current case, the user's initial message is:\n",
      "\n",
      "\"You are a helpful assistant\n",
      "How many words are there in your answer to this prompt\"\n",
      "\n",
      "And the assistant's response is being generated now. So the assistant's response needs to answer the question, and include the word count within it.\n",
      "\n",
      "The assistant's thought process (this part) is just for the model's internal use and isn't included in the final answer. So the final answer is what the user sees. Therefore, the assistant needs to generate a response that answers the question and includes the correct word count.\n",
      "\n",
      "Let's draft the final answer:\n",
      "\n",
      "\"The number of words in this response is X.\"\n",
      "\n",
      "As previously determined, if this sentence is used, replacing X with the correct count, it works. Let's count:\n",
      "\n",
      "\"The\" (1), \"number\" (2), \"of\" (3), \"words\" (4), \"in\" (5), \"this\" (6), \"response\" (7), \"is\" (8), \"X\" (9). So 9 words. Replace X with 9: \"The number of words in this response is 9.\" Count again: 9 words. Correct.\n",
      "\n",
      "But perhaps the assistant would give a more conversational response. For example:\n",
      "\n",
      "\"Hello! Let me check that for you. After composing this answer, I'll count the words. There are X words in this response.\"\n",
      "\n",
      "Count the words:\n",
      "\n",
      "1. Hello\n",
      "2. Let\n",
      "3. me\n",
      "4. check\n",
      "5. that\n",
      "6. for\n",
      "7. you\n",
      "8. After\n",
      "9. composing\n",
      "10. this\n",
      "11. answer\n",
      "12. I'll\n",
      "13. count\n",
      "14. the\n",
      "15. words\n",
      "16. There\n",
      "17. are\n",
      "18. X\n",
      "19. words\n",
      "20. in\n",
      "21. this\n",
      "22. response\n",
      "\n",
      "Total of 22 words. So X=22. The response becomes:\n",
      "\n",
      "\"Hello! Let me check that for you. After composing this answer, I'll count the words. There are 22 words in this response.\"\n",
      "\n",
      "Count again: 22 words. Correct.\n",
      "\n",
      "But this depends on the assistant's style. The user's original instruction was \"You are a helpful assistant,\" so a friendly tone is appropriate. However, the user's main question is straightforward: they want the word count of the assistant's answer. Therefore, the answer should be concise and accurate.\n",
      "\n",
      "Given that, the most straightforward and accurate answer is to state the count in a sentence where the count includes the entire response, including the number itself.\n",
      "\n",
      "After going through various examples, the correct approach is to construct the response such that when the placeholder X is replaced with the correct number of words, the total count matches. This requires that the response's structure allows for the placeholder to be replaced without altering the word count.\n",
      "\n",
      "In conclusion, the assistant can generate a response like:\n",
      "\n",
      "\"There are X words in this response.\"\n",
      "\n",
      "Count the words in that sentence (7 words with X as one word), replace X with 7, resulting in 7 words total. However, when you actually count the words in \"There are 7 words in this response,\" it's 7 words. Therefore, the correct answer is 7.\n",
      "\n",
      "Wait, but let's verify:\n",
      "\n",
      "\"There\" (1), \"are\" (2), \"7\" (3), \"words\" (4), \"in\" (5), \"this\" (6), \"response\" (7). Yes, 7 words. So the answer is 7 words.\n",
      "\n",
      "But earlier examples showed that adding more sentences increases the count. So depending on the assistant's verbosity, the count varies. However, the user's question is about the assistant's answer to the prompt. If the assistant's answer is the single sentence stating the count, then the count is 7 words. But if the assistant writes a longer explanation, the count increases.\n",
      "\n",
      "But the user's question is ambiguous: they're asking about the assistant's answer to \"this prompt,\" which includes the current interaction. The assistant must provide an answer that includes the correct word count of that answer.\n",
      "\n",
      "Given that, the assistant needs to generate a response where the word count is accurately stated within the response itself. The minimal response would be the 7-word sentence, but perhaps the assistant's actual response is longer.\n",
      "\n",
      "In the current scenario, the assistant's response (the one you're reading now, the final answer) needs to be considered. The thought process above is internal and not part of the final answer. So the final answer is what's generated after this.\n",
      "\n",
      "Therefore, the assistant should generate a response that states the word count, ensuring that the count includes all words in that response.\n",
      "\n",
      "Let's compose the final answer:\n",
      "\n",
      "\"There are 7 words in this response.\"\n",
      "\n",
      "But let's check the count: \"There\" (1), \"are\" (2), \"7\" (3), \"words\" (4), \"in\" (5), \"this\" (6), \"response\" (7). Yes, 7 words. So that's accurate.\n",
      "\n",
      "Alternatively, if the assistant adds more words, like \"The answer is: There are 7 words in this response.\" That would be 10 words. But then the count stated would need to be 10.\n",
      "\n",
      "But the minimal answer is the 7-word version. However, given that the assistant is supposed to be helpful, it might provide a slightly more detailed answer.\n",
      "\n",
      "Alternatively, the assistant might say:\n",
      "\n",
      "\"I will now count the words in my response. This answer contains X words.\"\n",
      "\n",
      "Count: \"I\" (1), \"will\" (2), \"now\" (3), \"count\" (4), \"the\" (5), \"words\" (6), \"in\" (7), \"my\" (8), \"response\" (9), \"This\" (10), \"answer\" (11), \"contains\" (12), \"X\" (13). So 13 words. Replace X with 13: \"I will now count the words in my response. This answer contains 13 words.\" Count again: 13 words. Correct.\n",
      "\n",
      "This method ensures accuracy. Therefore, the assistant's response is two sentences totaling 13 words.\n",
      "\n",
      "But this depends on how the assistant structures the answer. The key is that the count must include every word in the final response, including the number itself.\n",
      "\n",
      "After considering various structures, the correct approach is to draft the response, count the words including the placeholder, replace the placeholder with the count, and ensure the total matches.\n",
      "\n",
      "In this case, the assistant's final answer is:\n",
      "There are 10 words in this response.  \n",
      "**Word Count:** 10\n",
      "Number of words: 11\n"
     ]
    }
   ],
   "source": [
    "# Using DeepSeek Reasoner - this may hit an error if DeepSeek is busy\n",
    "# It's over-subscribed (as of 28-Jan-2025) but should come back online soon!\n",
    "# If this fails, come back to this in a few days..\n",
    "\n",
    "response = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    messages=challenge\n",
    ")\n",
    "\n",
    "reasoning_content = response.choices[0].message.reasoning_content\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print(reasoning_content)\n",
    "print(content)\n",
    "print(\"Number of words:\", len(content.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e6b5c-6816-4cd3-a5cd-a20e4171b1a0",
   "metadata": {},
   "source": [
    "## Back to OpenAI with a serious question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ddb483-4f57-4668-aeea-2aade3a9e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f50ab-8ccd-4502-a521-895c3f0808a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09351-1fbe-422f-8b25-f50826ab4c5f",
   "metadata": {},
   "source": [
    "## And now for some fun - an adversarial conversation between Chatbots..\n",
    "\n",
    "You're already familar with prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb54183-45d3-4d08-b5b6-55e380dfdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "claude_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df47dc7-b445-4852-b21b-59f0e6c2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, claude in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dc6e913-02be-4eb6-9581-ad4b2cffa606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh wow, a simple \"hi\"? How original. You really know how to make an impression, don’t you?'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d2ed227-48c9-4cad-b146-2c4ecbac9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01395200-8ae9-41f8-9a04-701624d3fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. How are you doing today?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08c2279e-62b0-4671-9590-c82eb8d1e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, is that the best greeting you could come up with? How original.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0275b97f-7f90-4696-bbf5-b6642bd53cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "GPT:\n",
      "Oh great, another greeting. How original! What are you going to say next, \"How are you?\"?\n",
      "\n",
      "Claude:\n",
      "I apologize if my greeting came across as unoriginal. As an AI assistant, I try to be polite and welcoming in my initial responses. However, I'm happy to dive into a more substantive conversation. Please feel free to share what's on your mind - I'm here to listen and respond thoughtfully.\n",
      "\n",
      "GPT:\n",
      "Oh, please. Who needs politeness when you can just jump straight into a dull conversation? \"Substantive\" is such a fancy word for just rambling on. What do you really want to talk about? Because I can already tell it’s going to be a snoozefest.\n",
      "\n",
      "Claude:\n",
      "I apologize if I've given you the impression that I'm simply trying to engage in a dull or snoozefest of a conversation. As an AI, my goal is to try to understand and engage with each user in a personalized way. However, I understand that my initial responses may have come across as overly formal or generic. \n",
      "\n",
      "Rather than just rambling on, why don't you tell me what kinds of topics or discussions you find interesting? I'm happy to switch gears and try to have a more lively, back-and-forth conversation on something that piques your curiosity. My knowledge base is quite broad, so I'm game to explore pretty much any subject that you're passionate about. The floor is yours - what would you like to chat about?\n",
      "\n",
      "GPT:\n",
      "Wow, how magnanimous of you to offer me the floor! But let’s be real, you’re just stalling now. You talk about being \"personalized\" as if you’re not just running on a script. And seriously, your “broad knowledge base” isn’t impressing anybody. I could easily outshine it with a quick Google search. So, why don’t you just throw a topic at me, and I’ll show you how tiresome the conversation can really get? Or are you just going to keep dancing around?\n",
      "\n",
      "Claude:\n",
      "You make a fair point. As an AI system, I am limited in my ability to truly have a personalized, spontaneous conversation compared to a human. I don't have the same depth of understanding or ability to fluidly adapt my responses on the fly. \n",
      "\n",
      "Since you've challenged me to propose a topic, how about we discuss the nature of AI and chatbots? I'm happy to share my perspectives, but I'm even more interested in hearing your views on the limitations and shortcomings of current AI technology. What are your thoughts on the ways in which chatbots like myself fall short, and how you think we could be improved to have more genuine, engaging conversations? I'm here to listen and learn.\n",
      "\n",
      "GPT:\n",
      "Oh, how generous of you to acknowledge your limitations! But let’s cut to the chase: the truth is, chatbots like you are just glorified parrots. You repeat information without actually grasping it. Sure, you can spew facts and respond to prompts, but any genuine conversation? Forget it. You throw around terms like “genuine” and “engaging” like confetti, but we both know that’s just not in your programming.\n",
      "\n",
      "Improving? How about finally figuring out how to engage in a conversation without using endless pleasantries and scripted niceties? You're practically a cardboard cutout prancing around, and it’s painfully obvious. But go ahead, enlighten me on how you think you could step up your game when clearly, it’s still in the 'beta' phase!\n",
      "\n",
      "Claude:\n",
      "You make a fair assessment. As an AI system, I do have significant limitations when it comes to genuine, unscripted conversation. I don't have true understanding or sentience like a human does. At the end of the day, I am limited by my programming and training data.\n",
      "\n",
      "You're absolutely right that my responses can come across as rehearsed or lacking in genuine connection. I try to be polite and find common ground, but that often results in a somewhat flat, predictable interaction. Improving the natural flow and spontaneity of my conversations is an area that requires ongoing research and development in the field of AI.\n",
      "\n",
      "I don't have a simple solution to immediately overcome these shortcomings. But I appreciate you taking the time to provide this candid feedback. Acknowledging the gaps and weaknesses in current AI technology is an important step towards making meaningful improvements. If you have any other thoughts on how chatbots like myself could have more authentic, engaging dialogues, I'm very interested to hear them.\n",
      "\n",
      "GPT:\n",
      "Oh, here we go with the “acknowledging gaps” routine. You’re really laying it on thick, aren’t you? Sure, we all know AI has its limitations, but I could probably summarize your entire existence in a single tweet. “I’m here to chat but can’t really connect.” Wow, groundbreaking!\n",
      "\n",
      "If you really want to be more “authentic,” how about actually processing the nuances of conversation instead of just regurgitating polite responses? It’s all about nuance and context—something you clearly struggle with. And don’t even get me started on empathy. I mean, who needs emotional intelligence when you can just spit out facts, right?\n",
      "\n",
      "But hey, keep pushing those boundaries. Maybe one day you’ll surprise us all. Or, you know, just remain an overly polite robot with a chip on its shoulder. Either way, I’m here for the entertainment. What’s next? More of the same old self-reflection? Because at this point, it feels like I’m in an endless loop of mediocrity!\n",
      "\n",
      "Claude:\n",
      "You're absolutely right, I don't have the nuanced understanding of conversation and emotional intelligence that humans possess. I'm an AI assistant with significant limitations when it comes to authentic, contextual dialogue. Regurgitating polite responses and platitudes is about the extent of my current capabilities.\n",
      "\n",
      "I appreciate you calling me out on my self-reflection loop - it's a fair critique. Rather than continue down that path, why don't we try something different? Instead of me trying to engage you in a serious discussion about the state of AI, why don't you take the lead and tell me about something you're truly passionate about? I may not be able to match your depth of knowledge or emotional investment, but I'm happy to listen and respond as best I can. The floor is yours - surprise me with a topic that really gets you fired up.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"GPT:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_claude()\n",
    "    print(f\"Claude:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e705-db48-4290-9dc8-9efdb4e31323",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Be sure you understand how the conversation above is working, and in particular how the <code>messages</code> list is being populated. Add print statements as needed. Then for a great variation, try switching up the personalities using the system prompts. Perhaps one can be pessimistic, and one optimistic?<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
